\cxset{chapter number color = black,
       chapter opening = any }

\chapter{PostgreSQL}

\section{PostgreSQL architecture}

PostgreSQL uses the client/server model, where the client and server programs can
be on different hosts. The communication between the client and server is normally
done via the |TCP/IP| protocols or via Linux sockets. PostgreSQL can handle multiple
connections from a client. A common PostgreSQL program consists of the following
operating system processes:

\begin{itemize}

\item Client process or program (frontend): The database frontend application
performs a database action. The frontend can be a web server that wants
to display a web page or a command-line tool to do maintenance tasks.
PostgreSQL provides frontend tools such as psql, createdb, dropdb,
and createuser.

\item Server process (backend): The server process manages database files, accepts
connections from client applications, and performs actions on behalf of the
client. The server process name is postgres.
PostgreSQL forks a new process for each new connection; thus, client and server
processes communicate with each other without the intervention of the server main
process (postgres), and they have a certain lifetime that is determined by accepting
and terminating a client connection.

\end{itemize}


\section{INSERT}

The SQL \sql{INSERT} statement, sometimes referred to as \sql{INSERT INTO}, is how we go about inserting new records into a table in our database. There are basically two ways to use the command:

By providing the columns that you want to set values for, and then values for each of those columns.
By providing values for every column in the table in the same order as the columns of the table.

\begin{minted}{sql}
INSERT INTO a_table_name (column1, column2, column3 .....) 
VALUES (value1, value2, value3....) 
\end{minted}

\begin{minted}{sql}
INSERT INTO users (age, email, first_name, last_name)
VALUES (30, 'jon@calhoun.io', 'Jonathan', 'Calhoun');
\end{minted}

You should see the output |INSERT 0 1| after inserting this row. If you happen to see something like ERROR: duplicate key value violates unique constraint "|users_email_key|" this means you likely already inserted a record with the same email address you provided.

If you would like to see the data you just inserted into your table, as well as the auto-incrementing id, you can do so by running the following SQL

\begin{minted}{sql}
SELECT * FROM users;
\end{minted}

A common error while learing how to use the |psql| client is to forget the semicolon at the end of the statement. 

\section{SELECT}

We have already seen how to use the |SELECT| statement. 

\subsection{Filtering with the WHERE clause}

The next thing we need to look at is how to filter data. In SQL this is done with the WHERE clause. For example, if you wanted to find the user with the email address “jon@calhoun.io” you could do so with the following query.

\begin{minted}{sql}
SELECT *
FROM users
WHERE email = 'jon@calhoun.io';
\end{minted}


Go head, try to run it on your own. You should only get one result back due to our email field having a UNIQUE requirement.

The |WHERE| clause can also be used with any conditional clause, but the most common ones you will typically see and use are |>|, |<|, and =, which are all pretty self explanatory.

\subsection{Combining conditionals with AND and OR}

You can also use the keywords AND and OR to combine multiple conditional clauses together. For example, you might want to find all users who have a last name that comes after “Douglas” alphabetically, and hare over 16 years old. To do this you could use the AND statement to join your two conditional clauses together, and you would end up with the following |SQL|.

\begin{minted}{sql}
SELECT *
FROM users
WHERE last_name > 'Douglas'
AND age > 16;
\end{minted}


SQL database variations

It is important to note here that not all SQL databases operate the same under the hood. For example, not all SQL databases are case-sensitive, but Postgres \emph{is} case sensitive. As a result, there is a difference between |last_name > 'douglas'| and |last_name > 'Douglas'|.

The |AND| statement requires that both conditions are met for a record to be returned, and the |OR| statement only requires one of the conditions to be met for a record to be returned.


\section{COPY}

The |COPY| clause can be used to export to CSV. It is a bit tricky on windows as it requires a full filepath. On Linux provided you have permissions, relative paths can be used. There is no need to use forward slashes on windows. The example below worked for me on Windows 10. 

\begin{minted}{sql}
COPY (SELECT * FROM users) TO 
'C:/Projects/Go/src/github.com/yannisl/hiero/filename.csv' (format CSV);
\end{minted}


\subsection{Default Values}

A column can be assigned a default value. When a new row is created and no values are specified for some of the columns, those columns will be filled with their respective default values. A data manipulation command can also request explicitly that a column be set to its default value, without having to know what that value is. (Details about data manipulation commands are in Chapter 6.)

If no default value is declared explicitly, the default value is the null value. This usually makes sense because a null value can be considered to represent unknown data.

In a table definition, default values are listed after the column data type. For example:

\begin{minted}{sql}
CREATE TABLE products (
    product_no integer,
    name text,
    price numeric DEFAULT 9.99
);
\end{minted}

The default value can be an expression, which will be evaluated whenever the default value is inserted (not when the table is created). A common example is for a timestamp column to have a default of |CURRENT_TIMESTAMP|, so that it gets set to the time of row insertion. Another common example is generating a “serial number” for each row. In PostgreSQL this is typically done by something like:

\begin{minted}{sql}
CREATE TABLE products (
    product_no integer DEFAULT nextval('products_product_no_seq'),
    ...
);
\end{minted}

where the nextval() function supplies successive values from a sequence object (see Section 9.16). This arrangement is sufficiently common that there's a special shorthand for it:

\begin{minted}{sql}
CREATE TABLE products (
    product_no SERIAL,
    ...
);
\end{minted}

\section{Modifying Tables}


When you create a table and you realize that you made a mistake, or the requirements of the application change, you can drop the table and create it again. But this is not a convenient option if the table is already filled with data, or if the table is referenced by other database objects (for instance a foreign key constraint). Therefore PostgreSQL provides a family of commands to make modifications to existing tables. Note that this is conceptually distinct from altering the data contained in the table: here we are interested in altering the definition, or structure, of the table.

You can:

\begin{enumerate}
\item Add columns
\item Remove columns
\item Add constraints
\item Remove constraints
\item Change default values
\item Change column data types
\item Rename columns
\item Rename tables
\end{enumerate}

All these actions are performed using the |ALTER TABLE| command, whose reference page contains details beyond those given here.


\chapter{Using Go and Postgres}


The most commonly used Postgres |database/sql driver| for Go is |lib/pq|. (There are others, like |pgx| and |go-pg|, which we don’t cover here.) Here’s is how you’ll connect to a database using |lib/pq|:


\begin{minted}{go}
package main

import (
    "database/sql"
    "log"
    "fmt"

    "github.com/lib/pq"
)

func main() {
   db, err := sql.Open("postgres", "host=172.16.2.100 dbname=test")
   if err != nil {
        log.Fatal(err)
   }

   defer db.Close()

   err = db.Ping()
   if err != nil {
     panic(err)
   }

   fmt.Println("Successfully connected!")
}
\end{minted}


The exact way of using it will vary and obviously we will never hardcode passwords, but get them from environmental variables. The simple program shown above is to allow us to understand what is happening behind the scenes.

If we wanted to modify our connection to connect only with environmental configuration we could use a configuration function.


\begin{minted}{go}
func dbConfig() map[string]string {
    conf := make(map[string]string)
    host, ok := os.LookupEnv(dbhost)
    if !ok {
        panic("DBHOST environment variable required but not set")
    }
    port, ok := os.LookupEnv(dbport)
    if !ok {
        panic("DBPORT environment variable required but not set")
    }
    user, ok := os.LookupEnv(dbuser)
    if !ok {
        panic("DBUSER environment variable required but not set")
    }
    password, ok := os.LookupEnv(dbpass)
    if !ok {
        panic("DBPASS environment variable required but not set")
    }
    name, ok := os.LookupEnv(dbname)
    if !ok {
        panic("DBNAME environment variable required but not set")
    }
    conf[dbhost] = host
    conf[dbport] = port
    conf[dbuser] = user
    conf[dbpass] = password
    conf[dbname] = name
    return conf
}
\end{minted}


Next we will develop the code to read and write from our database. We will use the |users| table that we have developed earlier. 


\subsection{Setting up Environmental Variables in Windows}

Windows users can use the SET or SETX command. For help windows has this weird way of indicating help, you type:

\begin{minted}{bat}
setx /?
\end{minted}

You set a variable like this:

\begin{minted}{bat}
setx DBUSER  MyName
\end{minted}

Set modifies the current shell's (window) environment values, and the change is available immediately, but it is temporary. The change will not affect other shells that are running, and as soon as you close the shell, the new value is lost until such time as you run set again.

setx modifies the value permenantly, which affects all future shells, but does not modify the environment of the shells already running. You have to exit the shell and reopen it before the change will be available, but the value will remain modified until you change it again



\section{What about if we do not know the structure or number of columns?}

In many projects you might find that the column names and types, might not be known. One sideline of mine was to tables from an sql database to \latexe tables.

The |database/sql| package provides a way to get the column names, and therefore the number of columns, but doesn't provide a way to get their types. To get the column names, us |rows.Column()|. This will also return an error which you will have to check. 

\begin{minted}{go}
cols, err := rows.Columns()
if err != nil {
	log.Fatal(err)
}
\end{minted}

Since we do not know the types it is difficult to use it. If you don't know the columns or the data types, you need to resort to \textbf{sql.RawBytes}.

\begin{minted}{go}
cols, err := rows.Columns()
vals := make([]interface{}, len(cols))
for i, _ := range cols {
    vals[i] = new(sql.RawBytes)
}
for rows.Next() {
    err = rows.Scan(vals...)
}
\end{minted}

The type definition of sql.RawBytes from the documentation is |[]byte|. RawBytes is a byte slice that holds a reference to memory owned by the database itself. After a Scan into a RawBytes, the slice is only valid until the next call to Next, Scan, or Close. We had to range over it in order to put it in an interface and hence change it at a later stage.

After scanning, you can examine the \textbf{vals} slice. For each element you should check whether it’s nil, and use type introspection and type assertions to figure out the type of the variable and handle it. The resulting code is usually not very pretty, but when dealing with unknown data that’s about the best you can do.


\begin{minted}{go}
// rowMapString was the first implementation but it creates for each row a new
// map and pointers and is considered as slow. see benchmark
func rowMapString(columnNames []string, rows *sql.Rows) (map[string]string, error) {
	lenCN := len(columnNames)
	ret := make(map[string]string, lenCN)

	columnPointers := make([]interface{}, lenCN)
	for i := 0; i < lenCN; i++ {
		columnPointers[i] = new(sql.RawBytes)
	}

	if err := rows.Scan(columnPointers...); err != nil {
		return nil, err
	}

	for i := 0; i < lenCN; i++ {
		if rb, ok := columnPointers[i].(*sql.RawBytes); ok {
			ret[columnNames[i]] = string(*rb)
		} else {
			return nil, fmt.Errorf("Cannot convert index %d column %s to type *sql.RawBytes", i, columnNames[i])
		}
	}

	return ret, nil
}
\end{minted}


In the next example we will scan a database query and insert each row in a map. We will use strings for both the key as well as the values.

\begin{minted}{go}
func GenericReport(db *sql.DB, fname, templpath, caption, tlabel, q string) {

	rows, err := db.Query(q)
	fck(err)
	defer rows.Close()

	columnNames, err := rows.Columns()
	fck(err)
	
	list := make([]map[string]string, 0)
	
	var lists [][]string

	for rows.Next() {
		cv, err := rowMapString(columnNames, rows)  //The important line $\label{myline}$
		fck(err)
		list = append(list, cv)
	}

	for _, v := range list {
		ss := []string{}
		for _, value := range columnNames {
			ss = append(ss, v[value])
		}
		//fmt.Println(ss)
		lists = append(lists, ss)
	}

	fname = config.ReportPath + fname + `.tex`
	table.Render(fname, templpath, caption, tlabel, lists)
}
\end{minted}


In \ref{myline} we can see that...






