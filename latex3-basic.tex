\makeatletter\@specialfalse\makeatother
\parindent1em
\chapter{The Basic LaTeX3 Syntax and Approach}
 \label{ch:l3intro}
 \cxset{epigraph width=0.7\textwidth}
 \epigraph{A final hint: listen carefully to what language users say they
want, until you have an understanding of what they really want. Then
find some way of achieving the latter at a small fraction of the cost
of the former. This is the test of success in language design, and
of progress in programming methodology. Perhaps these two are the same
subject anyway.}{C.A.R. Hoare, 1973}

		
\epigraph{Frank, in case you needed encouragement, please bear this in mind: I'm very much down at the blunt end of (La)TeX -- almost a total end-user. Following an earlier recommendation in this Q\&A, I visited the expl3 manual and was scared witless... Hope you can understand that---it's not a complaint, just an indication of the intellectual/experience distance from here to there.}{---Brent.Longborough Mar 2 '12 at 9:02 at \href{https://tex.stackexchange.com/questions/45838/what-can-i-do-to-help-the-latex3-project/46427\#46427}{SX.TX}}
 
Niklaus Wirth, the developer of the Pascal language long back in the 70’s wrote a paper titled \emph{On the Design of Programming Languages}. In his paper Wirth advocated that an important aspect of language design is \emph{simplicity}. He later on described the lessons learnt from his own works as:\footnote{\protect\url{http://chrisposkitt.com/tag/wirth/}}:

\begin{enumerate}
\item Writing a program is difficult.
\item Writing a correct program is even more so.
\item Writing a publishable program is exacting.
\item Programs are not written. They grow!
\item Controlling growth needs much discipline.
\item Reducing size and complexity is the triumph.
\item Programs must not be regarded as code for computers, but as literature for humans.
\end{enumerate}

The LaTeX3 syntax can only be described with some awe as `different’, although it retains some remnants of 
\tex’s syntax retaining the backslash, it is so different that many developers and package writers have resisted its adoption irrespective of the fact that it offers some solid code. 

Resistance to the language is understandable and noticed early by Computer Science pioneers. Hoare wrote:

\cxset{quotation font-size=\normalsize}
\begin{quotation}
A necessary condition for the achievement of any of these objectives
is the utmost simplicity in the design of the language. Without simplicity,
even the language designer himself cannot evaluate the consequences of his
design decisions. Without simplicity, the compiler writer cannot achieve
even reliability, and certainly cannot construct compact, fast and
- efficient compilers. But the main beneficiary of simplicity is the user
of the language. In all spheres of human intellectual and practical
activity, from carpentry to golf, from sculpture to space travel, the
true craftsman is the one who thoroughly understands his tools. And this
applies to programmers too. A programmer who fully understands his
language can tackle more complex tasks, and complete them quicker and
more satisfactorily than if he did not. In fact, a programmer's need
for an understanding of his language is so great, that it is almost
impossible to persuade him to change to a new one. No matter what the
deficiencies of his current language, he has learned to live with them;
he has learned how to mitigate their effects by discipline and documentation,
and even to take advantage of them in ways which would be impossible
in a new and cleaner language which avoided the deficiency.

It therefore seems especially necessary in the design of a new
programming language, intended to attract programmers away from their
current high level language, to pursue the goal of simplicity to an
extreme, so that a programmer can readily learn and remember all its
features, can select the best facility for each of his purposes, can
fully understand the effects and consequences of each decision, and can
then concentrate the major part of his intellectual effort to understanding
his problem and his programs rather than his tool.
\end{quotation}

I have been programming for many years and have a disdain for languages that---as Hoare
put it--- I cannot remember ``all its features’’.  LaTeX3 has not achieved the level of simplicity required in its core. As a tool it fails the simplicity test and effortful learning is necessary to use it effectively. Currently there are probably less than twenty developers that understand it fully. 

Where, \latex3 excels is its architecture, overall plan and direction and modularizing the code to an extend that the required tools reside in logically set modules or classes in \latex’s terminology. What I can promise you, once you master it, there is no looking back. 

\section{Is it stable?}

One question that often arises is the stability of the current \latex~3 code base. Of course the degree to which software are “stable enough” depends on the requirements. Joseph Wright, answering a question on the SX.TX Q\&A site wrote:

\begin{latexquotation}
If you want 'will never change again', then plain TeX is probably your best bet. Knuth does still fix bugs periodically, but most things are now likely to be regarded as 'features' rather than bugs and so it's extremely likely that a document written in plain today will still work totally unchanged in tens of years (assuming TeX systems continue to be available).

The LaTeX2e kernel is also very unlikely to change further, and so is almost if not quite as stable as TeX itself. The team do fix bugs and do allow a bit more leeway than Knuth does, but even so it's extremely unlikely anything will change with LaTeX2e at the kernel level in a way that would require changes in documents.

There are some LaTeX packages one could reasonably decide to use which are also very stable and unlikely to see changes, either because they are no longer being actively developed or because the authors are careful to only change code related to genuine bugs or new, non-breaking, features. Obvious candidates are keyval, graphicx, etc.: probably there is actually quite a decent list, depending on your requirements.

In the case of the LaTeX3 packages l3kernel and l3packages, 'stable' does not extend as far as 'you will never have to make a change to a document using them', at least at this stage. What it means is that the team will not be making 'arbitrary' changes and will document/announce when this happens. Most of l3kernel is 'done', with the plans primarily focused on addition of new functionality rather than altering existing code. However there are a few places where we know some change may be required, and that will be announced on the LaTeX-L mailing list and documented. Even within these changes, 'breaking' (non-back-compatible) alterations will be small in number, but there is at least one of them we still need to do.

In the case of xparse, \docAuxCommand*{DeclareDocumentCommand} and so on are 'stable' in the sense that they will only be augmented, not removed, but there could be some changes on the more esoteric functions (for example, there are questions centred on the \textbf{g} argument type).

Thus 'stable enough' depends on your use case. If you can live with 'will have to make very occasional changes based on documented and scheduled updates' then expl3 is entirely usable. (I and others use if routinely in packages.) On the other hand, if you want 'this code must work with no changes with all future releases of support code' then we are not quite there yet.
\end{latexquotation}

\section{Getting started}

Other than the obvious of making sure you have the latest distribution from the LaTeX3 repository, 
the first step is to understand the conventions used by the \LaTeX3 developers. Macros are termed \meta{functions} and \meta{variables}. Macro names in general use the underscore and the colon in their names.
This is by design and to be honest is part of what many developers are unhappy about. It does cut down on the readability of the code and the longer names are more difficult to remember. This type of naming convention is similar to Hungarian notation, in which the name of a variable or function indicates its type  or its intended use and it does not have a lot of friends.


Consider the \tex primitive \docAuxCommand*{meaning}. In \latex3 it has been remapped to \docAuxCommand*{token_to_meaning:N}. Similarly \docAuxCommand*{scan_stop:} has been let to \docAuxCommand*{relax}.

\begin{texexample}{Getting started}{ex:meaning}
\ExplSyntaxOn
\def\somevar{one}
\token_to_meaning:N \scan_stop:  \\
\meaning\somevar \\
\token_to_meaning:N \somevar \\
\token_to_meaning:N \token_to_meaning:N
\ExplSyntaxOff
\end{texexample}

The part that comes after the colon is termed the \emph{function signature}. For example in |token_to_meaning:N|, the function signature is the \textbf{N}. The individual letter “N” is termed the argument specifier. Another important part is the prefix of the functions. There are some exceptions but the prefix normally indicates the module where the macro has been defined. So |\token_to_meaning:N|  can be found in the |l3token| package.\footnote{The term module and package are used interchangeably by the \latex3 Team.}

Consider the definition of a simple function  |\phd_print_xy:nn| that accepts two values $x,y$ and prints them. This can be defined by one of the |cs_| type functions.

One way we could have defined the macro using  \tex would be:

\begin{teXXX}
\def\phdprint #1#2{x#1 y#2}
\end{teXXX}

Using \latexe we would have probably used |\newcommand| and if the definition was internal to a package used an |@|. 

\begin{teXXX}
\makeatletter
\newcommand\phd@print [2] {x#1 y#2}
\makeatother
\end{teXXX}

In \latex3 we would use |\cs_set_no_par:Npn|.

\begin{teXXX}
\cs_set_nopar:Npn \phd_print_xy:nn #1#2 { x #1 y #2 }
\end{teXXX}

So what is this mysterious |\cs_set_nopar:Npn|? We can find out by peeking at its meaning. This is shown in Example~\ref{ex:somemeaning}. As you can see behind the new dress is Knuth’s same old |\def|.

\begin{texexample}{The meaning of a command}{ex:somemeaning}
\ExplSyntaxOn
\token_to_meaning:N  \cs_set_nopar:Npn
\ExplSyntaxOff
\end{texexample}

But first let us examine the |:Npn| part of the |\cs_set_no_par:Npn| more carefully. What this means is the macro has three arguments. The first one is N-type which is a \tex token. The second one is p-type, which denotes normal \tex parameters such as |#1#2|. Lastly the n-type can be either a single token or a bracketted parameter. 

There are many more argument specifiers. Functions can be found with different argument specifiers and these are termed \emph{variants}. Recall that a macro can be defined using |\def|, |\edef| or a |\csname| construct. The argument specifier to the |\cs_set_no_par| can be varied to achieve it. (See example~\ref{ex:somemeaning}) 

\begin{texexample}{The meaning of a command}{ex:somemeaning}
\ExplSyntaxOn
\token_to_meaning:N  \cs_set_nopar:Npx\\
\token_to_meaning:N  \cs_set_nopar:cpx\\
\ExplSyntaxOff
\end{texexample}

Consider the use  of a |\csname| construct to define our |\phd_print_xy:nn| macro. The example that follows

\begin{texexample}{ex:csname}{ex:csname}

\ExplSyntaxOn
\expandafter\def\csname phd_print_xy:nn\endcsname #1 #2{x#1 y#2}

\token_to_meaning:N \phd_print_xy:nn\\

\cs_set_nopar:cpx {phd_print_xy:nn} #1 #2 {x#1 y#2}
\token_to_meaning:N \phd_print_xy:nn\\
\ExplSyntaxOff
\end{texexample} 

By using \latex3 functions, we do not need to use the |\expandafter| macro. The macros are generally longer but the overall code is shorter.

So far we have used the |\token_to_meaning:N|. \latex3 offers similar commands to get the argument specification, the prefix and the replacement specification. When we specify a macro in \latex3 we can capture all its constituent parts and handle them individually if we want.

\begin{texexample}{Dissecting a macro}{}
\ExplSyntaxOn
\cs_set_nopar:Npn \phd_print_xy:nn #1#2! { x #1 y #2 }
\token_to_meaning:N \phd_print_xy:nn \\
\token_get_arg_spec:N \phd_print_xy:nn  \\
\token_get_prefix_spec:N \phd_print_xy:nn\\
\token_get_replacement_spec:N \phd_print_xy:nn\\
\ExplSyntaxOff
\end{texexample}


Some argue that the syntax is not syntactic sugar but syntactic cyanide that changes the look and feel both of \latexe and \tex command macros. You should think of |expl3| as a new computer language. It does introduce consistency and offers a full repertoire of tools. The syntactic strangeness of the language does introduce barriers to mastering it, but the advantages far outweigh the difficulties of the language.


The eye tends to miss the argument specifier, it is important to note that the macro
name is \cmd{\test\_something:nn} and not \cmd{\test\_something} and the factory command is |\cs_new:Npn| and not |\cs_new|. If you have been programming using traditional macros this is a common mistake that you will accidentally make and you will get an |error unknown| message.

\section{Where from here}

The chapters of this book follow a logical sequence for learning the language, although most of them can be read as stand alone. 

The steps in learning any computer language require a logical sequence of study:

\begin{enumerate}
\item Understanding the syntax
\item Variables and datatypes
\item Numbers and assignments
\item Control Structures
\item Functions
\item Data structures
\item Ecosystem
\end{enumerate}

In the next chapter we would study the creation of functions in more detail. This is the most important skill to master before you proceed with the rest of the programming constructs, such as iteration, arithmetic operations etc.



\chapter{Defining Functions and Variables}

\section{Defining functions}
There are two main methods to define functions. In the first method you are required to use parameter tex, whereas in the second this can be left out, as it can be inferred from the argument specification of the function being defined. The functions used to create other functions can be found in both forms. For example:

\begin{texexample}{Using parameter text}{}
\ExplSyntaxOn
\cs_set_nopar:Npn \phd_print:n #1 {#1}
\token_to_meaning:N \phd_print:n\\

\cs_set_nopar:Nn  \phd_print:n  {#1}


\token_to_meaning:N \phd_print:n\\
\ExplSyntaxOff
\end{texexample}



 Functions can be created with no requirement that they are declared
 first (in contrast to variables, which must always be declared).\footnote{This primarily refers to variables that require a \tex register.}
 Declaring a function before setting up the code means that the name
 chosen will be checked and an error raised if it is already in use.
 The name of a function can be checked at the point of definition using
 the \docAuxCommand*{cs_new}\ldots functions: this is recommended for all
 functions which are defined for the first time.

 There are three primary ways to define new functions, using |new|, |set| or |gset| variations.  The first one is similar to the \latexe |\newcommand|, and produces macros that will generate an error if there is an attempt to redefine them. The other two are variations of the |\def or \edef| and |\gdef or \xdef| \tex commands.
 
 All classes define a function to expand to the substitution text.
 Within the substitution text the actual parameters are substituted
 for the formal parameters (|#1|, |#2|, \ldots).
 
 \begin{description}
   \item[\texttt{new}]
     Create a new function with the \texttt{new} scope,
     such as \docAuxCommand* {cs_new:Npn}.  The definition is global and will result in
     an error if it is already defined.
   \item[\texttt{set}]
     Create a new function with the \texttt{set} scope,
     such as \docAuxCommand* {cs_set:Npn}. The definition is restricted to the current
     \TeX{} group and will not result in an error if the function is already
     defined.
   \item[\texttt{gset}]
     Create a new function with the \texttt{gset} scope,
     such as \docAuxCommand* {cs_gset:Npn}. The definition is global and
     will not result in an error if the function is already defined.
 \end{description}

  Finally, the functions in
 Subsections~\ref{sec:l3basics:defining-new-function-1}~and
 \ref{sec:l3basics:defining-new-function-2} are primarily meant to define
 \emph{base functions} only. Base functions can only have the following
 argument specifiers:
 \begin{description}
   \item[|N| and |n|] No manipulation.
   \item[|T| and |F|] Functionally equivalent to |n| (you are actually
     encouraged to use the family of |\prg_new_conditional:| functions
     described in Section~\ref{sec:l3prg:new-conditional-functions}).
   \item[|p| and |w|] These are special cases.
 \end{description}



 Within each set of scope there are different ways to define a function.
 The differences depend on restrictions on the actual parameters and
 the expandability of the resulting function.
 \begin{description}
   \item[\texttt{nopar}]
      Create a new function with the \texttt{nopar} restriction,
      such as \docAuxCommand*{cs_set_nopar:Npn}. The parameter may not contain
      \docAuxCommand*{par} tokens.
   \item[\texttt{protected}]
      Create a new function with the \texttt{protected} restriction,
      such as \docAuxCommand*{cs_set_protected:Npn}. The parameter may contain
      \docAuxCommand*{par} tokens but the function will not expand within an
      \texttt{x}-type expansion.
 \end{description}
 
 
\subsection{Defining new functions using parameter text}

Theses function are \TeX ish in style, as compared to those functions that use the signature to automatically detect the number of parameters and are more \LaTeX-like. They are mainly used with the |:Npn| signature specification.

\begin{texexample}{Using parameter text}{}
\ExplSyntaxOn
\cs_new:Npn \phd_print:n #1 {#1}

\token_to_meaning:N \cs_new:Npn\\
\token_to_meaning:N \phd_print:n\\
\ExplSyntaxOff
\end{texexample}

\begin{docCommand}{cs_new:Npn} {\meta{function} \meta{parameters} \marg{code}}
Creates \meta{function} to expand to \meta{code} as replacement text. Within the \meta{code}, the
\meta{parameters} (\#1, \#2, etc.) will be replaced by those absorbed by the function. The
definition is \textbf{global} and an error will result if the \meta{function} is already defined.
Variants with |cpn,Npx,cpx| are predefined by the kernel.
\end{docCommand}

The |:Npn| form can also be used even if there is no parameter text. However this is considered a constant variable and is preferred to be coded as a |tl| such.

\begin{texexample}{Usage of the macro}{ex:csnew}
\ExplSyntaxOn
  \cs_new:Npn \copyrightfootnote: 
    {
      \footnotetext{Copyright~(2014-2015)~of~Yiannis~Lazarides,~distributed~
      under~the~\LaTeX{}~Project~Public~License~(LPPL).}
    }
  \copyrightfootnote:
\ExplSyntaxOff
\end{texexample}

An important point to note is if you use the function signature type you will get an error if the trailing |:| is not used in the macro name. 

\begin{teXXX}
\cs_new:Nn \copyrightafootnote 
  {
    ...
  }
\copyrightafootnote
\end{teXXX}

This will produce an error:\ExplSyntaxOn\copyrightfootnote:\ExplSyntaxOff

\begin{verbatim}
! LaTeX error: "kernel/missing-colon"
! Function '\copyrightafootnote' contains no ':'.
! See the LaTeX3 documentation for further information.
! For immediate help type H <return>.
\end{verbatim}

If the function is redefined, it will produce an error, similar to \latexe |\newcommand|. However, do note that the |set| family of commands can silently overwrite it. 

\begin{texexample}{Usage of the macro \protect\string\cs\_gset:Npn}{ex:csnew}
\ExplSyntaxOn
\cs_gset:Npn \copyrightfootnote: {\footnotetext{Copyright~(2014-2015)~of~Yiannis~Lazarides,~distributed~
under~the~\LaTeX{}~Project~Public~License~(LPPL).}}
\copyrightfootnote:
\ExplSyntaxOff
\end{texexample}

\begin{docCommand}{cs_new_nopar:Npn} {\meta{function} \meta{parameters} \marg{code}}
Creates \meta{function} to expand to \meta{code} as replacement text. Within the \meta{code}, the
\meta{parameters} (\#1, \#2, etc.) will be replaced by those absorbed by the function. When the
\meta{function} is used the hparametersi absorbed cannot contain \par tokens. The definition
is global and an error will result if the \meta{function} is already defined.
\end{docCommand}

\begin{texexample}{Meaning}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_new_nopar:Npn
\ExplSyntaxOff
\end{texexample}

\begin{docCommand}{cs_new_protected:Npn}{\meta{function} \meta{parameters} \marg{code}}
Creates \meta{function} to expand to \meta{code} as replacement text. Within the hcodei, the
hparametersi (\#1, \#2, etc.) will be replaced by those absorbed by the function. The
\meta{function} will not expand within an x-type argument. The definition is global and an
error will result if the hfunctioni is already defined.
\end{docCommand}

\begin{docCommand}{cs_new_protected_nopar:Npn}{\meta{function} \meta{parameters} \marg{code}}
Creates \meta{function} to expand to \meta{code} as replacement text. 
When the \meta{function} is used the \meta{parameters} absorbed cannot contain \docAuxCommand*{par} tokens. The hfunctioni
will not expand within an x-type argument. The definition is global and an error will
result if the \meta{function} is already defined.
\end{docCommand}

This brings us to the end of the |new| type functions that can be used for function definitions. They all have variants of the form |cpn| and |cpx| and the base function for edef also is available. You can consult the manual for more definitions.

\subsubsection{The set type functions}

The rest of the commands are variations using the |set| form of function creating macros. These do not issue a 
warning if redefined.

 \begin{docCommand}{cs_set:Npn} {\meta{function} \meta{parameters} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level.
\end{docCommand}

\begin{texexample}{Meaning}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_set:Npn
\ExplSyntaxOff
\end{texexample}

As can be seen from the example this is |\protected \long \def|. The |\cs_set_nopar:Npn| in the maeaning in the example is described next and is simply an equivalent function to |\def|.

 \begin{docCommand} {cs_set_nopar:Npn}{\meta{function} \meta{parameters} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   When the \meta{function} is used the \meta{parameters} absorbed
   cannot contain \cs{par} tokens. The assignment of a meaning
   to the \meta{function} is restricted to the current \TeX{} group
   level.
 \end{docCommand}
 
 \begin{texexample}{Meaning \textbackslash cs\_set\_nopar:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_set_nopar:Npn
\ExplSyntaxOff
\end{texexample}
 

\begin{docCommand}{cs_set_protected:Npn} {\meta{function} \meta{parameters} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level. The \meta{function} will
   not expand within an \texttt{x}-type argument.
 \end{docCommand}
 \begin{texexample}{Meaning \textbackslash cs\_set\_protected:Npn}{}
 \ExplSyntaxOn
 \token_to_meaning:N \cs_set_protected:Npn
\ExplSyntaxOff
\end{texexample}
 


\begin{docCommand}{cs_set_protected_nopar:Npn}{\meta{function} \meta{parameters} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   When the \meta{function} is used the \meta{parameters} absorbed
   cannot contain \cs{par} tokens. The assignment of a meaning
   to the \meta{function} is restricted to the current \TeX{} group
   level. The \meta{function} will not expand within an
   \texttt{x}-type argument.
\end{docCommand}
\begin{texexample}{Meaning \textbackslash cs\_set\_protected\_nopar:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_set_protected_nopar:Npn
\ExplSyntaxOff
\end{texexample}
 
Next the above are made available by the \latex3 kernel but all in the |global| form of the command. The syntax is identical except they use |cs_gset|.


\begin{docCommand} {cs_gset:Npn}{\meta{function} \meta{parameters} \marg{code}}
   Globally sets \meta{function} to expand to \meta{code} as replacement
   text. Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
  \emph{etc.}) will be replaced by those absorbed by the function.
  The assignment of a meaning to the \meta{function} is \emph{not}
   restricted to the current \TeX{} group level: the assignment is
   global.
\end{docCommand}
\begin{texexample}{Meaning \textbackslash cs\_gset:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_gset:Npn
\ExplSyntaxOff
\end{texexample}

\begin{docCommand}{cs_gset_nopar:Npn} {\meta{function} \meta{parameters} \marg{code}}
   Globally sets \meta{function} to expand to \meta{code} as replacement
   text. Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   When the \meta{function} is used the \meta{parameters} absorbed
   cannot contain \cs{par} tokens. The assignment of a meaning to the
   \meta{function} is \emph{not} restricted to the current \TeX{}
   group level: the assignment is global.
\end{docCommand}
\begin{texexample}{Meaning \textbackslash cs\_gset\_nopar:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_gset_nopar:Npn
\ExplSyntaxOff
\end{texexample}


\begin{docCommand} {cs_gset_protected:Npn} {\meta{function} \meta{parameters} \marg{code}}
   Globally sets \meta{function} to expand to \meta{code} as replacement
   text. Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   The assignment of a meaning to the \meta{function} is \emph{not}
   restricted to the current \TeX{} group level: the assignment is
   global. The \meta{function} will not expand within an
   \texttt{x}-type argument.
\end{docCommand}
\begin{texexample}{Meaning \textbackslash cs\_gset\_protected:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_gset_protected:Npn
\ExplSyntaxOff
\end{texexample}

\begin{docCommand}{cs_gset_protected_nopar:Npn} {\meta{function} \meta{parameters} \marg{code}}
   Globally sets \meta{function} to expand to \meta{code} as replacement
   text. Within the \meta{code}, the \meta{parameters} (|#1|, |#2|,
   \emph{etc.}) will be replaced by those absorbed by the function.
   When the \meta{function} is used the \meta{parameters} absorbed
   cannot contain \cs{par} tokens. The assignment of a meaning to the
   \meta{function} is \emph{not} restricted to the current \TeX{}
   group level: the assignment is global. The \meta{function} will
   not expand within an \texttt{x}-type argument.
\end{docCommand}
\begin{texexample}{Meaning \textbackslash cs\_gset\_protected\_nopar:Npn}{}
\ExplSyntaxOn
\token_to_meaning:N \cs_gset_protected_nopar:Npn
\ExplSyntaxOff
\end{texexample}

This brings us to the end of the functions available to the developer for defining macros. It’s a lot of them. In the next section some more functions are defined, this time using the signature of the function the function are created automatically without the need to type in the parameter text.


\subsection{Defining new functions using the signature}

The functions outlined below have a simpler form in that they create other commands without the need to specify their arguments. The number of parameters is detected automatically from the function signature. Which method is the best is obvious up to the user preferences.\footnote{See discussion at SX.TX \protect{\url{http://tex.stackexchange.com/questions/240675/differences-in-latex3-function-generation-methods}}} 


\begin{docCommand}{cs_new:Nn}{\meta{function}\marg{code}}
Creates \meta{function} to expand to \meta{code} as replacement text. A nice feature is that within the \meta{code}
the number of parameters is detected automatically from the function signature. These \meta{parameters} (\#1, \#2, etc.) will be replaced by those absorbed by the function. The definition is global and an error will result if the \meta{function} is already defined.\footnote{The definitions of the commands have been taken mostly verbatim from the documentation of the package.}


\begin{texexample}{Signature}{ex:signature}
\ExplSyntaxOn
\cs_new:Nn \exampleone:nn {}
\cs_new:Nn \exampletwo:nn{#1 #2}
\exampleone:nn {one}{two}

\exampletwo:nn{one }{two}

\texttt\textbackslash\cs_to_str:N\exampleone:nn
\ExplSyntaxOff
\end{texexample}
\end{docCommand}

 
 
 
\begin{docCommand}{cs_new_nopar:Nn}{\meta{function} \marg{code}}
   Creates \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.  When the \meta{function} is used the \meta{parameters}
   absorbed cannot contain \docAuxCommand*{par} tokens. The definition is global and
   an error will result if the \meta{function} is already defined.
 \end{docCommand}

\begin{docCommand}{cs_new_protected:Nn}{\meta{function} \marg{code}}
   Creates \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function. The \meta{function} will not expand within an \texttt{x}-type
   argument. The definition is global and
   an error will result if the \meta{function} is already defined.
\end{docCommand}


%
% \begin{function}
%   {
%     \docAuxCommand*_new_protected_nopar:Nn, \docAuxCommand*_new_protected_nopar:cn,
%     \docAuxCommand*_new_protected_nopar:Nx, \docAuxCommand*_new_protected_nopar:cx
%   }
%   \begin{syntax}
%     \docAuxCommand*{cs_new_protected_nopar:Nn} \meta{function} \Arg{code}
%   \end{syntax}
%   Creates \meta{function} to expand to \meta{code} as replacement text.
%   Within the \meta{code}, the number of \meta{parameters} is detected
%   automatically from the function signature. These \meta{parameters}
%   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
%   function.  When the \meta{function} is used the \meta{parameters}
%   absorbed cannot contain \docAuxCommand*{par} tokens. The \meta{function} will not
%   expand within an \texttt{x}-type argument. The definition is global and
%   an error will result if the \meta{function} is already defined.
% \end{function}

Similarly to the |cs_new| commands the |cs_set| functions create other commands, this time
with a local scope. This pattern is followed right through the kernel.

 \begin{docCommand}{cs_set:Nn}{\meta{function}\marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level.
 \end{docCommand}

\begin{docCommand}{cs_set_nopar:Nn}{\meta{function}\marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.  When the \meta{function} is used the \meta{parameters}
   absorbed cannot contain \docAuxCommand*{par} tokens.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level. This is the \tex primitive \docAuxCommand*{def}
\end{docCommand}

\begin{teXXX}
\tex_let:D \cs_set_nopar:Npn \tex_def:D
748 \tex_let:D \cs_set_nopar:Npx \tex_edef:D
749 \etex_protected:D \cs_set_nopar:Npn \cs_set:Npn
750                     { \tex_long:D \cs_set_nopar:Npn }
751 \etex_protected:D \cs_set_nopar:Npn \cs_set:Npx
752                   { \tex_long:D \cs_set_nopar:Npx }
753 \etex_protected:D \cs_set_nopar:Npn \cs_set_protected_nopar:Npn
754 { \etex_protected:D \cs_set_nopar:Npn }
755 \etex_protected:D \cs_set_nopar:Npn \cs_set_protected_nopar:Npx
756 { \etex_protected:D \cs_set_nopar:Npx }
757 \cs_set_protected_nopar:Npn \cs_set_protected:Npn
758 { \etex_protected:D \tex_long:D \cs_set_nopar:Npn }
759 \cs_set_protected_nopar:Npn \cs_set_protected:Npx
760 { \etex_protected:D \tex_long:D \cs_set_nopar:Npx }
\end{teXXX}
\ExplSyntaxOn
\meaning\cs_new:Npn
\ExplSyntaxOff


\begin{docCommand}{cs_set_protected:Nn}{\meta{function}\marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function. The \meta{function} will not expand within an \texttt{x}-type
   argument.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level.
 \end{docCommand}

\begin{docCommand}{cs_set_protected_nopar:Nn}{ \meta{function} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.  When the \meta{function} is used the \meta{parameters}
   absorbed cannot contain \docAuxCommand*{par} tokens. The \meta{function} will not
   expand within an \texttt{x}-type argument.
   The assignment of a meaning to the \meta{function} is restricted to
   the current \TeX{} group level.
 \end{docCommand}

The next commands create functions with global scope.

 \begin{docCommand}{cs_gset:Nn}{ \meta{function} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.
   The assignment of a meaning to the \meta{function} is  global.
 \end{docCommand}

 \begin{docCommand}{cs_gset_nopar:Nn}{ \meta{function} \marg{code}}
   Sets \meta{function} to expand to \meta{code} as replacement text.
   Within the \meta{code}, the number of \meta{parameters} is detected
   automatically from the function signature. These \meta{parameters}
   (|#1|, |#2|, \emph{etc.}) will be replaced by those absorbed by the
   function.  When the \meta{function} is used the \meta{parameters}
   absorbed cannot contain \docAuxCommand*{par} tokens.
   The assignment of a meaning to the \meta{function} is global.
 \end{docCommand}
 

\section{Copying control sequences}

Control sequences (not just functions as defined above) can be set to have the same
meaning using the functions described here. Making two control sequences equivalent
means that the second control sequence is a copy of the first (rather than a pointer to
it). Thus the old and new control sequence are not tied together: changes to one are not
reflected in the other. These are syntactic replacements for |\let|.

\begin{texexample}{Let}{}
\ExplSyntaxOn
\cs_set_nopar:Nn \testa: {AAA}
\cs_set_eq:NN\testb: \testa:
\token_to_meaning:N \testa:  \\
\cs_set_nopar:Nn \testa: {BBBB}
\testb:  \\
\token_to_meaning:N \testb:  \\
\token_to_meaning:N \testa:  \\
\testa:\\
\testb: \\
\meaning\cs_set_eq:NN

% check if equal to \let
\token_to_meaning:N \let\\
\token_to_meaning:N \cs_set_equal:NN
\ExplSyntaxOff
\end{texexample}

 In the following text \enquote{cs} is used as an abbreviation for
 \enquote{control sequence}.

 \begin{docCommand}{cs_new_eq:NN} {\meta{cs1} \meta{cs2}}
   Globally creates \meta{control sequence 1} and sets it to have the same
   meaning as \meta{control sequence 2} or |<token>|.
   The second control sequence may
   subsequently be altered without affecting the copy.
\end{docCommand}


\begin{docCommand}{cs_set_eq:NN} {\meta{cs1} \meta{cs2}}
   Sets \meta{control sequence1} to have the same meaning as
   \meta{control sequence2} (or |<token>|).
   The second control sequence may subsequently be
   altered without affecting the copy. The assignment of a meaning
   to the \meta{control sequence1} is restricted to the current
   \TeX{} group level.
 \end{docCommand}


\begin{docCommand} {cs_gset_eq:NN} {\meta{cs1} \meta{cs2}}
   Globally sets \meta{control sequence1} to have the same meaning as
   \meta{control sequence2} (or |<token>|).
   The second control sequence may subsequently be
   altered without affecting the copy. The assignment of a meaning to
   the \meta{control sequence1} is \emph{not} restricted to the current
   \TeX{} group level: the assignment is global.
\end{docCommand}

\section{Undefining control sequences}

There are occasions where control sequences need to be deleted. This is handled in a
very simple manner by the use of 
|\cs_undefine:N| \meta{control sequence},
which sets \meta{control sequence} to be globally |undefined|.

\begin{texexample}{Undefining control sequences}{ex:undefine}
\ExplSyntaxOn
\cs_set_nopar:Npn \testa: {AAA}
\cs_set_nopar:cpn {testb} {AAA}

\cs_undefine:N \testa:
\cs_undefine:c {testb}
\token_to_meaning:N \cs_undefine:N\\

\token_to_meaning:N \testa:\\
\token_to_meaning:c {testb}\\
\token_to_meaning:N \token_to_meaning:c
\ExplSyntaxOff
\end{texexample}

The function would simply set the command to the \tex primitive |undefine|, as can be seen from the example.
There is another group of commands associated with constructor functions.

\section{Converting to and from control sequences}

\begin{docCommand}{cs_if_exist_use:N} {\meta{control sequence}}
Tests whether the \meta{control sequence} is currently defined (whether as a function or another
control sequence type), and if it does inserts the \meta{control sequence} into the input stream.
\end{docCommand}

\begin{docCommand}{cs_if_exist_use:NTF} {\meta{control sequence}}
Tests whether the \meta{control sequence} is currently defined (whether as a function or another
control sequence type), and if it does inserts the \meta{control sequence} into the input stream
followed by the \meta{true code}.
\end{docCommand}

\begin{texexample}{Converting to and from control sequences}{ex:ifexists}
\ExplSyntaxOn
\cs_if_exist_use:NTF \test {}{\FALSE}
\ExplSyntaxOff
\end{texexample}

Note that numerous times, I have typed |\cs_if_exists_use:NTF| rather than the more grammatical  |\cs_if_exist_use:NTF| with consequent errors. Grammar is hardwired in the brain and it requires mental effort to write ungrammatical commands. This is an issue that needs to be addressed by the \latex3 developers. 

The famous |\csname| is mapped in this section of the module as well. Unpredictably, it got a shorter name, but a weird suffix |w|! It deserves both as it is the workhorse of \tex. The remapped commands are formally described in the manual as shown below:

\begin{docCommand}{cs:w} {\meta{control sequence name} \texttt{cs\_end:}}
Converts the given \meta{control sequence name} into a single control sequence token. This
process requires one expansion. The content for \meta{control sequence name} may be literal
material or from other expandable functions. The \meta{control sequence name} must, when
fully expanded, consist of character tokens which are not active: typically, they will be
of category code 10 (space), 11 (letter) or 12 (other), or a mixture of these.
\end{docCommand}


\section{User Commands}

All the commands above are at the programming level. For the development of user commands the \pkgname{xparse} package provides some extremely useful commands. These are dealt under \nameref{ch:xparse}
on page \pageref{ch:xparse}.

\begin{teXXX}
\NewDocumentCommand{\kant}{s>{\SplitArgument{1}{-}}O{1-7}}
  {
   \group_begin:
   \IfBooleanTF{#1} (*@\label{starargument}@*)
     { \cs_set_eq:NN \kgl_par: \kgl_star: }
     { \cs_set_eq:NN \kgl_par: \kgl_nostar: }
     \kgl_process:nn #2
    \kgl_print:
   \group_end:
  }
\end{teXXX}

In Line~\ref{starargument} we test for the star version of the command and then we continue examining the optional argument |O{1-7}|, but first and here is the magic, we have passed the argument through a pre-processing macro named |\SplitArgument|, which has captured the splitted argument and placed it, into two braced macros. It then passes it to a second macro |\getwords| that expects two mandatory aruguments and which handles the typesetting of the two words.
    
\begin{texexample}{Split Argument}{}    
\NewDocumentCommand{\separatewords}{>{\SplitArgument{1}{-}}m}{\getwords#1}
\NewDocumentCommand{\getwords}{ m m }{First word:#1  Second~Word:#2}
\separatewords{mail-coach}

\separatewords{mail}

\end{texexample}    

A similar example see TX.SX.\footnote{\protect{\url{http://tex.stackexchange.com/questions/154941/new-command-in-tex-for-fraction/154950\#154950}}}


\chapter{LaTeX3 Control Structures}
 \section{The boolean data type}

 This section describes a boolean data type which is closely
 connected to conditional processing as sometimes you want to
 execute some code depending on the value of a switch
 (\emph{e.g.},~draft/final) and other times you perhaps want to use it as a
 predicate function in an |if_predicate:w| test. The problem of the
 primitive \docAuxCommand*{if_false:} and \docAuxCommand*{if_true:} tokens is that it is not
 always safe to pass them around as they may interfere with scanning
 for termination of primitive conditional processing. In \latex3
 two canonical booleans ar employed: \docAuxCommand*{c_true_bool} or
\docAuxCommand{c_false_bool}. Besides preventing problems as described above. This also let
to the implementation of  a simple boolean parser supporting the
 logical operations And, Or, Not, \emph{etc.}\ which can then be used on
 both the boolean type and predicate functions.

 All conditional |\bool_| functions except assignments are expandable
 and expect the input to also be fully expandable (which will generally
 mean being constructed from predicate functions, possibly nested).
 
Before a boolean can be used it needs to be created with \docAuxCommand{bool_new:N}, but first let us make sure we understand what a boolean is. A Boolean data type is a data type, having two values (usually denoted \emph{true} and \emph{false}), intended to represent the truth values of logic and Boolean algebra. It is named after George Boole, who first defined an algebraic system of logic in the mid 19th century. 

So how does \latex3 construct a boolean? If we examine the code, which we will in a small example, we can see that a boolean variable is just another macro that either stores 0 or 1. If the value is odd then the boolean is \emph{true} else the boolean is \emph{false}. 

\begin{teXXX}
\tex_chardef:D \c_true_bool = 1 ~
\tex_chardef:D \c_false_bool = 0 ~
\end{teXXX}

\begin{teXXX}
 \cs_new_protected:Npn \bool_new:N #1 { \cs_new_eq:NN #1 \c_false_bool }
 \cs_generate_variant:Nn \bool_new:N { c }
\end{teXXX}

When a new boolean is constructed it is always set to false, as is evident from its code. 

Here is the formal syntax of the |\bool_new:N| function.

 \begin{docCommand}{bool_new:N}{\meta{boolean}}
   Creates a new \meta{boolean} or raises an error if the
   name is already taken. The declaration is global. The
   \meta{boolean} will initially be \texttt{false}. Once the boolean is created
   it can be set to logical true or false using \docAuxCommand*{bool_set_false:N} and \docAuxCommand*{bool_set_true:N}.
 \end{docCommand}
 
\begin{texexample}{Booleans}{}
\ExplSyntaxOn
\bool_new:N \mybool
\bool_set_false:N \mybool
\bool_if:NTF\mybool { \PASS } { \FAIL }
\ExplSyntaxOff
\end{texexample}
 

 
The real strength of the \latex~3 macros are the convenience of providing for |Or| and |And|
operations, negation etc.  and for its ability to evaluate fully boolean expressions. 

\begin{docCommand}{bool_if:nTF}{\marg{boolean expression} \marg{true code} \marg{false code}}
   Tests the current truth of \meta{boolean expression}, and
   continues expansion based on this result. The
   \meta{boolean expression} should consist of a series of predicates
   or boolean variables with the logical relationship between these
   defined using |&&| (\enquote{And}), \verb"||" (\enquote{Or}),
   |!| (\enquote{Not}) and parentheses. Minimal evaluation is used
   in the processing, so that once a result is defined there is
   not further expansion of the tests. 
\end{docCommand}   



\begin{texexample}{Booleans}{}
\ExplSyntaxOn
\bool_new:N\chapterfloat
\bool_new:N\numberfloat
\bool_set_false:N\chapterfloat
\bool_set_true:N\numberfloat

\bool_if:nTF {\chapterfloat || \numberfloat}  { \TRUE }{ \FALSE }

\bool_if:nTF {\chapterfloat && \numberfloat}  { \TRUE }{ \FALSE }

\ExplSyntaxOff
\end{texexample}

\subsection{\textbackslash if\_meaning}

The primitive |ifx| conditional has an equivalent in \latex3. This is called more semantically \docAuxCommand*{if_meaning:w}. This compares two tokens based on their meaning.



\begin{texexample}{Test ifx}{}
\ExplSyntaxOn
\group_begin:
  \cs_set_nopar:Npn \a: {BBB}
  \cs_set_nopar:Npn \b: {BBB~}
  \cs_set_nopar:Npn \c: {B~BB}
  
  \if_meaning:w \a:\b: \PASS \else: \FAIL \fi:
  \if_meaning:w \a:\c: \PASS \else: \FAIL \fi:
  
  \token_to_meaning:N \b:\\
  \token_to_meaning:N \a:  
\group_end:  
\ExplSyntaxOff
\end{texexample}

\begin{texexample}{LaTeX2e booleans}{}
\makeatletter
\ExplSyntaxOn
\if@mainmatter
     in~main~text
   \else
    not~in~main~text  
\fi    

 \meaning\@mainmattertrue\\
\bool_new:N \phd_mainmatter_bool 
\meaning\phd_mainmatter_bool
\ExplSyntaxOff
\makeatother  
\end{texexample}

\section{Predicate functions}

Predicate functions are one of the more powerful features of |expl3|. What are predicate functions? They are macros that test a predicate (\emph{true} or \meta{false}) and branch to either a true or false branch or just a single branch depending on the signature of the function. The |expl3| package has numerous such functions for example:

\begin{teXXX}
 \str_if_eq:nnT {}{}{}
\end{teXXX}

accepts two strings and if true does something. The expl3 package, provides a function that can generate such predicate functions fairly easily.

\begin{docCommand}{prg_set_conditional:Npnn}{\meta {function name}: \meta{arg spec} \meta{parameters} \marg{conditions code}}

These functions create a family of conditionals using the same \meta{code} to perform the
test created. Those conditionals are expandable if \meta{code} is. The new versions will
check for existing definitions and perform assignments globally (cf. |\cs_new:Npn|) whereas
the set versions do no check and perform assignments locally (cf. |\cs_set:Npn|). The
conditionals created are dependent on the comma-separated list of \meta{conditions}, which
should be one or more of p, T, F and TF.
\end{docCommand}

\begin{teXXX}
\prg_set_conditional:Npnn \cs_if_exist:N #1 { p , T , F , TF }
 {
 \if_meaning:w #1 \scan_stop:
   \prg_return_false:
     \else:
        \if_cs_exist:N #1
           \prg_return_true:
        \else:
          \prg_return_false:
      \fi:
 \fi:
}
2556 \prg_new_conditional:Npnn \token_if_eq_meaning:NN #1#2 { p , T , F , TF }
2557 {
2558 \if_meaning:w #1 #2
2559 \prg_return_true: \else: \prg_return_false: \fi:
2560 }

2201 \prg_new_conditional:Npnn \mode_if_math: { p , T , F , TF }
2202 { \if_mode_math: \prg_return_true: \else: \prg_return_false: \fi: }

\prg_new_conditional:Npnn \int_if_even:n #1 { p , T , F , TF}
3321 {
3322 \if_int_odd:w \__int_eval:w #1 \__int_eval_end:
3323 \prg_return_false:
3324 \else:
3325 \prg_return_true:
3326 \fi:
3327 }
\end{teXXX}

\begin{texexample}{isEven}{}
\ExplSyntaxOn
\prg_new_conditional:Npnn \isEven:n #1 { p, T, F, TF}
{
 \if_int_odd:w \__int_eval:w #1 \__int_eval_end:
    \prg_return_false:
 \else:
    \prg_return_true:
 \fi:
}

\isEven:nTF {2045679}{\PASS}{\FAIL}
\isEven:nTF {1000000}{\PASS}{\FAIL}
\ExplSyntaxOff
\end{texexample}

A common need for programmers is the testing of an integer or real for positiveness  with expl3 we can use predicate functions. In Example~\ref{ex:positive} we define predicate functions \docAuxCommand*{isPositive:nTF} to test an integer expression and feed the results to a true or false branch or according to the function signature. 

\begin{texexample}{isPositive} {ex:positive}
\ExplSyntaxOn
\prg_new_conditional:Npnn \isPositive:n #1 { p, T, F, TF}
{
\if_int_compare:w  \__int_eval:w #1 \__int_eval_end: >\__int_eval:w 0 \__int_eval_end:
     \prg_return_true:
\else:
    \prg_return_false:
\fi:          
}

\prg_new_conditional:Npnn \isNegative:n #1 { p, T, F, TF}
{
\if_int_compare:w  \__int_eval:w #1 \__int_eval_end: >\__int_eval:w 0 \__int_eval_end:
     \prg_return_false:
\else:
    \prg_return_true:
\fi:          
}
\cs_new:Npn \assert_is_positive:n #1 
   {
     \isPositive:nTF {#1} {\PASS #1} {\FAIL #1}
   }  
\cs_new:Npn \assert_is_negative:n #1 
   {
     \isNegative:nTF {#1} {\PASS #1} {\FAIL #1}
   } 
\assert_is_positive:n {2059+23-1245}
\assert_is_positive:n {-2059+23-1245}
\assert_is_negative:n {2059+23-1245}
\assert_is_negative:n {-2059+23-1245}
\ExplSyntaxOff
\end{texexample}

In the next example  we will use a common \tex trick to determine if a number is an integer or not. When \tex tries to convert a number to roman it will not scan past a minus sign .

\begin{texexample}{isInteger} {ex:isinteger}
\ExplSyntaxOn
\prg_set_conditional:Npnn \isInteger:n #1 { p, T, F, TF}
{
   \tl_if_blank:oTF {#1}{\prg_return_false:}
    {
     \tl_if_blank:oTF {  \__int_to_roman:w -\__int_eval:w #1 \__int_eval_end: }
		   {
		     \prg_return_true:
		   }
		   {
		     % not a number, but can be a negative number
		     \prg_return_false:
	         }
   }   
}

\cs_new:Npn \assert_is_integer:n #1 
   {
     \isInteger:nTF {#1} {\PASS\ ~~ #1} {\FAIL\ ~~ #1}\par
   }  
\assert_is_integer:n { }   
\assert_is_integer:n { 12}
\assert_is_integer:n {2059+1}
\assert_is_integer:n {-2059}
\assert_is_integer:n {2059}
%\assert_is_integer:n {ABC-1245}
\ExplSyntaxOff
\end{texexample}

The tests will pass provided even if we pass a  |numexpr|, but the assertion will fails if the number is negative. 
What we should have done was to test first if the head of the string was a (-) and then send it for further processing. 

\begin{texexample}{Testing the head of a string for the minus sign}{ex:string}
\ExplSyntaxOn
\cs_set:Npn \test:#1#2;{
   \str_if_eq:nnTF {-}{#1}{\PASS\par }{\FAIL\par }
   \str_if_eq:nnTF {-}{#1#2}{\PASS\par }{\FAIL\par }
}
\test:-;
\test:-12356;
\test:1234;
\ExplSyntaxOff
\end{texexample}

This passes all the comparison correctly, so we will have to re-write our function to test for the minus sign, before we send it to the main function. The reason I wrote the two tests above, is that a minus sign cannot be considered a number. 

\chapter{LaTeX3 Boxes}

\epigraph{If you go far enough back, your genome connects you with bacteria, butterflies, and barracuda---the great chain of being linked together through DNA.}{---Spencer Wells}

The \pkgname{l3box} package, provides numerous commands that deal with boxes. Before you delve in the code you should be familiar with \tex’s concepts of boxes such as \docAuxCommand*{hbox} and \docAuxCommand*{vbox}. The full repertoire of commands is available, as well as additional helper functions to reduce the number of commands necessary when storing content in boxes. There is also an additional package for handling the \latexe type |\fbox| and |\makebox| commands, still in experimental stage called \pkgname{xbox}. The latter also is attempting to provide some integration with the \pkgname{xcoffins} package which is an entirely new concept for box manipulation in \latex3. Most of the commands are just syntactic translations of the \latexe macros. 

Do they offer any advantage? I am not too sure if they do at this stage. When it comes to boxes, which is such a fundamental typographic concept users expect much more than these basic commands, however one needs to build up from more basic commands and these have to be re-defined to keep up with the spirit of \latex3.

\section{Storing content in boxes}

\tex’s concept of storing content in boxes is fundamental to any programming effort, where the dimensions of typeset material needs to be determined before further processing.

\subsection{Creating and initializing boxes}
\begin{docCommand}{box_new:N} {  \meta{box}}
   Creates a new \meta{box} or raises an error if the name is
   already taken. The declaration is global. The \meta{box} will
   initially be void.
\end{docCommand}
\begin{docCommand}{box_new:c}{\meta{box}}
   Creates a new \meta{box} or raises an error if the name is
   already taken. The declaration is global. The \meta{box} will
   initially be void.
\end{docCommand}

Normally three operations are involved. Creating an empty box or using one of the available temporary one, setting the contents in a horizontal or vertical or a combination of both of them, measuring them if necessary 
and then 

\begin{texexample}{Storing content in boxes}{l3box}
\ExplSyntaxOn
\box_new:c { textbox }
\hbox_set_to_wd:cnn { textbox } { 6cm } 
  {
    \tex_hsize:D 5cm
    \colorbox{spot!10}{\vbox:n  
       { \lorem }}
  }
\box_use:c {textbox}
\ExplSyntaxOff
\end{texexample}

The naming schemes are a bit unintuitive but this is inherited from \tex itself. To restrict the |\vbox| you need to set the |\hsize|.  

 \begin{docCommand}{box_move_right:nn}{\docAuxCommand*{box_move_right:nn} \marg{dimexpr} \marg{box function}}
 This function operates in vertical mode, and inserts the
  material specified by the \meta{box function}
  such that its reference point is displaced horizontally by the given
   \meta{dimexpr} from the reference point for typesetting, to the right
   or left as appropriate. The \meta{box function} should be
   a box operation such as |\box_use:N \<box>| or a \enquote{raw}
   box specification such as |\vbox:n { xyz }|.
 \end{docCommand}

 \begin{docCommand}{box_move_up:nn}{\docAuxCommand*{box_move_up:nn} \marg{dimexpr} \marg{box function}}
   This function operates in horizontal mode, and inserts the
   material specified by the \meta{box function}
   such that its reference point is displaced vertical by the given
   \meta{dimexpr} from the reference point for typesetting, up
   or down as appropriate. The \meta{box function} should be
   a box operation such as |\box_use:N \<box>| or a \enquote{raw}
   box specification such as |\vbox:n { xyz }|.
 \end{docCommand}
 
\begin{texexample}{Moving Boxes up or down}{l3boxdown}
\ExplSyntaxOn
\vbox_set:cn{textbox}{abcd}
A \box_move_down:nn{10pt}{\box_use:c {textbox}} 
\ExplSyntaxOff
\end{texexample}

 \section{Measuring and setting box dimensions}

\begin{docCommand}{box_dp:N}{\docAuxCommand*{box_dp:N} \meta{box}}
   Calculates the depth (below the baseline) of the \meta{box}
   in a form suitable for use in a \meta{dimension expression}.
\end{docCommand}

\begin{docCommand}{box_ht:N}{\docAuxCommand*{box_ht:N} \meta{box}}
   Calculates the height (above the baseline) of the \meta{box}
   in a form suitable for use in a \meta{dimension expression}.
  This is the \TeX{} primitive \docAuxCommand*{ht}.
 \end{docCommand}

% \begin{function}{\box_wd:N, \box_wd:c}
%   \begin{syntax}
%     \docAuxCommand*{box_wd:N} \meta{box}
%   \end{syntax}
%   Calculates the width of the \meta{box} in a form
%   suitable for use in a \meta{dimension expression}.
%   \begin{texnote}
%     This is the \TeX{} primitive \tn{wd}.
%   \end{texnote}
% \end{function}

\section{Horizontal Boxes}
\label{l3:hboxes}

So far we have discussed the boxing, unboxing and measuring of box dimensions. In the examples we have used
the \latex3 form of |\hbox| and |\vbox|.  Now time to lose our  beloved |source2e| favoured command \docAuxCommand*{hb@xt@} and friends. 

 \begin{docCommand}{hbox:n}{\docAuxCommand*{hbox:n} \marg{contents}}
   Typesets the \meta{contents} into a horizontal box of line width and then includes this box in the current list for typesetting.
   This is the \TeX{} primitive \docAuxCommand*{hbox}.
 \end{docCommand}

\begin{texexample}{Natural width boxes}{l3:hbox}
\ExplSyntaxOn
\hbox:n{\includegraphics[width=0.8\textwidth]{latex3}}
\ExplSyntaxOff
\end{texexample}

\begin{texexample}{Natural width boxes}{l3:hbox}
\ExplSyntaxOn
\hbox:n{\includegraphics[width=0.8\textwidth]{latex3}}
\ExplSyntaxOff
\end{texexample}


\begin{docCommand}{hbox_to_wd:nn}{\docAuxCommand*{hbox_to_wd:nn} \marg{dimexpr} \marg{contents}}
   Typesets the \meta{contents} into a horizontal box of width
   \meta{dimexpr} and then includes this box in the current list for
   typesetting.
\end{docCommand}

\begin{texexample}{Natural width boxes}{l3:hbox}
\ExplSyntaxOn
\DeclareDocumentCommand\PutImage{o m}{
  \IfNoValueTF{#1}
      {\putimage{#2}}
      {\putimage{#1}{#2}}
}

\noindent\hbox_to_wd:nn{0.3\textwidth}{\includegraphics[width=0.3\textwidth]{amato}}
\hbox_to_wd:nn{0.3\textwidth}{\includegraphics[width=0.3\textwidth]{amato}}
\ExplSyntaxOff

\noindent\hbox to 0.3\textwidth{\includegraphics[width=0.3\textwidth]{amato}}%
\hbox to 0.3\textwidth{\includegraphics[width=0.3\textwidth]{amato}}
\end{texexample}

Having set our goodbyes to |\hb@xt@| we also don’t feel very sorry for not having to type \% to eliminate wandering spaces. As we delve further into the intricacies of \latex3 we can also start appreciating its advantages.

% \begin{function}{\hbox_to_zero:n}
%   \begin{syntax} 
%     \docAuxCommand*{hbox_to_zero:n} \Arg{contents}
%   \end{syntax}
%   Typesets the \meta{contents} into a horizontal box of zero width
%   and then includes this box in the current list for typesetting.
% \end{function}

\section{Vertical Boxes}
The vertical box equivalents to \tex’s |\vbox|, |\vtop| are provided, as well as helper functions to store contents in a box typeset zero width boxes or lap them left, right or center. The commands are mostly syntactic sugar to the primitive commands. 

\begin{docCommand}{vbox:n}{\marg{contents}}
Typesets the \meta{contents} into a vertical box of natural height and includes this box in the current list for typesetting.
\end{docCommand}

\begin{docCommand}{vbox_to_ht:nn}{\marg{dimexpr}\marg{contents}}
Typesets the \meta{contents} into a vertical box of height \meta{dimexpr} and includes this box in the current list for typesetting.
\end{docCommand}

\begin{docCommand}{vbox_to_zero:n}{\marg{contents}}
Typesets the \meta{contents} into a vertical box of zero height and includes this box in the current list for typesetting.
\end{docCommand}

%\tcbset{listing options={
%              firstnumber=10, stepnumber=1, belowskip=0pt, 
%              escapeinside={(*@}{@*)},
%              backgroundcolor=\color{graphicbackground}
%              }}
\begin{texexample}{vboxes in LaTeX3}{l3:boxes}
\ExplSyntaxOn
    \fbox{\vbox:n{\lorem}}\par
    \fbox{\vbox_to_ht:nn {1.5cm}{\lorem}}\par
    \fbox{\vbox_to_zero:n {\lorem}}
\ExplSyntaxOff
\vspace*{1cm}
\end{texexample}

In Example~\ref{l3:boxes} we use \docAuxCommand*{vbox_to_ht:nn} and \docAuxCommand*{vbox_to_zero:n} to set text in two vertical boxes. The first one is typeset in a vertical box of 2cm height, whereas the second one in a box of zero height. The macro
|\fbox| which we discussed earlier in the \latexe boxes chapter, is also available in \latex3 but as part of the still under trial package \pkgname{xbox}.\footnote{To make matters more complicated, the version used in this document has been redefined further!} 



%\tcbset{listing options={
%              firstnumber=last, stepnumber=1, belowskip=0pt, 
%              escapeinside={(*@}{@*)},
%              backgroundcolor=\color{graphicbackground},
%              upquote=true,
%          }}
              
\begin{texexample}{vboxes in LaTeX3}{l3:boxes}
\ExplSyntaxOn
    \fbox{\vbox:n{\lorem}}\par
    \fbox{\vbox_to_ht:nn {1.5cm}{\lorem}}\par
    \fbox{\vbox_to_zero:n {\lorem}}
\ExplSyntaxOff
\vspace*{1cm}
\end{texexample}

\chapter{LaTeX3 xcoffins, special boxes for special typesetting}

\epigraph{The history of that name (as I remember it at least) goes way back to a stroll in some town in the UK sometime in the last century, probably 1997 (may have been Nottingham, but I don't remember) with David Carlisle and Chris Rowley and perhaps a few others on which we discussed those ideas about boxes with handles and somehow somebody came up with "rather like a coffin" and that is how it got born. And no, I don't remember whether it was David, Chris or myself.

Somehow the name stuck; initially as a working title when we first implemented a prototype, but later I must confess I rather liked it -- a bit morbit for sure, but also catchy :-) ... and it made for few a great lines in my talk in San Francisco, such as: Now in 2010 coffins are back – exhumed, cleaned up – and ready for display
what else can you hope for?}{---Frank Mittelbach}


%\tcbset{listing options={
%              firstnumber=10, stepnumber=1, belowskip=0pt, 
%              escapeinside={(*@}{@*)},
%              backgroundcolor=\color{graphicbackground},
%              upquote=true,
%          }}
          
 In \LaTeX3 terminology, a \enquote{coffin} is a box containing
 typeset material.\footnote{The term `coffin’ was probably coined by Frank Mittelbach (see \protect\url{http://tex.stackexchange.com/questions/147738/origin-of-the-latex3-term-coffin})} Along with the box itself, the coffin structure
 includes information on the size and shape of the box, which makes
 it possible to align two or more coffins easily. This is achieved
 by providing a series of `poles' for each coffin. These
 are horizontal and vertical lines through the coffin at defined
 positions, for example the top or horizontal centre. The points
 where these poles intersect are called \enquote{handles}. Two
 coffins can then be aligned by describing the relationship between
 a handle on one coffin with a handle on the second. In words, an
 example might then read
 \begin{quote}
   Align the top-left handle of coffin A with the bottom-right
   handle of coffin B.
 \end{quote}

 The locations of coffin handles are much easier to understand
 visually. Figure~\ref{fgr:handles} shows the standard handle
 positions for a coffin typeset in horizontal mode (left) and in
 vertical mode (right). Notice that the later case results in a greater
 number of handles being available. As illustrated, each handle
 results from the intersection of two poles. For example, the centre
 of the coffin is marked |(hc,vc)|, \emph{i.e.}~it is the
 point of intersection of the horizontal centre pole with the
 vertical centre pole. New handles are generated automatically when
 poles are added to a coffin: handles are \enquote{dynamic} entities.
 \NewCoffin \ExampleCoffin
\begin{figure}[htbp]
   \hfil
    \fboxsep2pc
     \colorbox{black}{\color{white}\begin{minipage}{0.4\textwidth}
     \SetHorizontalCoffin\ExampleCoffin
       {\color{white}\rule{1 in}{1 in}}
  \DisplayCoffinHandles\ExampleCoffin{yellow}
   \end{minipage}}
   \hfil
   \begin{minipage}{0.4\textwidth}
     \SetVerticalCoffin\ExampleCoffin{1 in}
       {\color{black!10!white}\rule{1 in}{1 in}}
     \DisplayCoffinHandles\ExampleCoffin{red}
   \end{minipage}
   \hfil
   \caption{Standard coffin handles: left, horizontal coffin; right,
     vertical coffin}
   \label{fgr:handles}
 \end{figure}


All coffin operations are local to the current \tex group with the exception
of coffin creation. Coffins are also “color safe”: in contrast to the code-level \docAuxCommand*{box_}\ldots.
functions there is no need to add additional grouping to coffins when dealing with color.

The user interface for the command is somewhat complicated. This is an area where the package
can be enhanced in the future and the sole reason is being kept under the \emph{experimental}
branch of \latex3.

\section{Getting Started}

Before a \meta{coffin} can be used, it must be allocated using \docAuxCommand*{NewCoffin}.

\begin{docCommand}{NewCoffin}{\meta{coffin}}
Before a \meta{coffin} can be used, it must be allocated using \docAuxCommand*{NewCoffin}. The name of the
hcoffini should be a control sequence (starting with the escape character, usually \textbackslash ), for
example

\begin{verbatim}
\NewCoffin\MyCoffin
\end{verbatim}

Coffins are allocated globally, and an error will be raised if the name of the \meta{coffin} is
not globally-unique.
\end{docCommand}

\begin{texexample}{Coffins}{ex:coffins}
  \NewCoffin \AnExampleCoffin
  \NewCoffin\Rulei
\end{texexample}

 \begin{docCommand}{SetHorizontalCoffin}{\docAuxCommand*{SetHorizontalCoffin} \meta{coffin} \marg{material}}
   Typesets the \meta{material} in horizontal mode, storing the result
   in the \meta{coffin}. The standard poles for the \meta{coffin} are
   then set up based on the size of the typeset material.
 \end{docCommand}

 \begin{docCommand}{SetVerticalCoffin}{\docAuxCommand*{SetVerticalCoffin} \meta{coffin} \marg{width} \marg{material}}
   Typesets the \meta{material} in vertical mode constrained to the
   given \meta{width} and stores the result in the \meta{coffin}. The
   standard poles for the \meta{coffin} are then set up based on the
   size of the typeset material.
 \end{docCommand}

In Example~\ref{ex:coffins2} we will create a horizontal coffin and then typeset it. 
 
%\tcbset{listing options={
%              firstnumber=last, stepnumber=1, belowskip=0pt, 
%              escapeinside={(*@}{@*)},
%              backgroundcolor=\color{graphicbackground},
%              upquote=true,
%          }}
          
\begin{texexample}{Creating coffins}{ex:coffins2}
\SetHorizontalCoffin\ExampleCoffin
   {\color{red}\rule{4cm}{1pc}}  
\SetHorizontalCoffin\Rulei
   {\color{blue}\rule{6cm}{1pc}}     
   
First coffin\hspace{0.9cm}\DisplayCoffinHandles\ExampleCoffin{black}\hspace{0.9cm}!
  
Second  coffin\hfill \DisplayCoffinHandles\Rulei{blue}

\meaning\Rulei
\end{texexample}
  
\paragraph{How to set the width } The rule was created using \latexe |\rule|  macro and then it was saved in a coffin box named |\ExampleCoffin|. The typesetting was done using |\DisplayCoffinHandles| 

In the next example, we will create a second rule and then demonstrate the joining operation. We will need two more coffins, one to hold the results and the other to hold the material for the second box.

\begin{texexample}{Joining Coffins}{ex:coffins3}
\NewCoffin\ExampleCoffinTwo
\NewCoffin\Result
\SetHorizontalCoffin\ExampleCoffin
   {\color{red}\rule{3cm}{1pc}} 
\SetHorizontalCoffin\ExampleCoffinTwo
   {\color{green}\rule{3cm}{1pc}}    
\JoinCoffins\Result\ExampleCoffin   
\JoinCoffins \Result[\ExampleCoffin-t,\ExampleCoffin-r] \ExampleCoffinTwo [b,l](0pt,2mm)
\TypesetCoffin\Result
\end{texexample}
 
The interesting, but complicated command is |\JoinCoffins|. This takes two arguments, the coffins to be joined, which in turn have optional commands, specifying how the coffins are joined at their poles. 
This is the key operation for coffins,  joining coffins to each other. This
 is always carried out such that the first coffin is the
 \enquote{parent}, and is updated by the alignment. The second
 \enquote{child} coffin is not altered by the alignment process.

 \begin{docCommand}{JoinCoffins}{ \docAuxCommand*{JoinCoffins} *
     ~~\meta{coffin1} [ \meta{coffin1-pole1} , \meta{coffin1-pole2} ]
     ~~\meta{coffin2} [ \meta{coffin2-pole1} , \meta{coffin2-pole2} ]
     ~~( \meta{x-offset} , \meta{y-offset} )}
   Joining of two coffins is carried out by the \docAuxCommand*{JoinCoffins}
   function, which takes two mandatory arguments: the \enquote{parent}
   \meta{coffin1} and the \enquote{child} \meta{coffin2}. All of the
   other arguments shown are optional.
 \end{docCommand}

   The standard \docAuxCommand*{JoinCoffins} functions joins \meta{coffin2} to
   \meta{coffin1} such that the bounding box of \meta{coffin1} after the
   process will expand. The new bounding box will be the smallest
   rectangle covering the bounding boxes of the two input coffins.
   When the starred variant of \docAuxCommand*{JoinCoffins} is used, the bounding
   box of \meta{coffin1} is not altered, \emph{i.e.}~\meta{coffin2} may
   protrude outside of the bounding box of the updated \meta{coffin1}.
   The difference between the two forms of alignment is best illustrated
   using a visual example. In Figure~\ref{fgr:alignment}, the two
   processes are contrasted. In both cases, the small red coffin has been
   aligned with the large grey coffin. In the left-hand illustration,
   the \docAuxCommand*{JoinCoffins} function was used, resulting in an expanded
   bounding box. In contrast, on the right \docAuxCommand*{AttachCoffin} was used,
   meaning that the bounding box does not include the area of the
   smaller coffin.
   
\begin{texexample}{Joining Coffins}{ex:coffins4}
\SetHorizontalCoffin\ExampleCoffin
   {\color{red}\rule{3cm}{1pc}} 
\SetHorizontalCoffin\ExampleCoffinTwo
   {\color{green}\rule{3cm}{1pc}}    
\JoinCoffins\Result\ExampleCoffin   
\JoinCoffins*\Result[\ExampleCoffin-l,\ExampleCoffin-b] \ExampleCoffinTwo [t,l](0pt,2mm)
\TypesetCoffin\Result
\end{texexample}   
   
\section{Controlling coffin poles}

 A number of standard poles are automatically generated when the coffin
 is set or an alignment takes place. The standard poles for all coffins
 are:
 \begin{marglist}
   \item[l] a pole running along the left-hand edge of the bounding
     box of the coffin;
   \item[hc] a pole running vertically through the centre of the coffin
     half-way between the left- and right-hand edges of the bounding
       box (\emph{i.e.}~the \enquote{horizontal centre});
   \item[r] a pole running along the right-hand edge of the bounding
     box of the coffin;
   \item[b] a pole running along the bottom edge of the bounding
     box of the coffin;
   \item[vc] a pole running horizontally through the centre of the
     coffin half-way between the bottom and top edges of the bounding
     box (\emph{i.e.}~the \enquote{vertical centre});
   \item[t] a pole running along the top edge of the bounding
     box of the coffin;
   \item[H] a pole running along the baseline of the typeset material
     contained in the coffin.
 \end{marglist}
 In addition, coffins containing vertical-mode material also
 feature poles which reflect the richer nature of these systems:
 \begin{itemize}
   \item[B] a pole running along the baseline of the material at the
     bottom of the coffin.
   \item[T] a pole running along the baseline of the material at the top
     of the coffin.
 \end{itemize}  
 
\section{A larger example}

Consider the book cover of Judy Estrin’s book, \emph{Closing the Innovation Gap} shown in Example~\ref{ex:covers}. The title elements have been carefully placed by the book designer. This sort
of cover page is within the possibilities of what can be programmed via \latex~3 and the package \pkgname{xcoffins}.

\begin{texexample}{Typesetting Cover Pages}{ex:covers}  
\bgroup
\parindent0pt
% For each element declare a new  coffin
\NewCoffin\ci
\NewCoffin\cii
\NewCoffin\ciii
\NewCoffin\civ

% Always better to give semantic names!
\NewCoffin\slogan
\NewCoffin\ImageCoffin
\NewCoffin\AuthorCoffin

% A convenient commant to set font a
\DeclareDocumentCommand\fonta{}
  {
      \color{white}\LARGE\bfseries\sffamily
  }

% Similar command for font b    
\DeclareDocumentCommand\fontb{}
  {
      \color{white}\large\bfseries\sffamily
  }  
\SetHorizontalCoffin\Result{}
\SetHorizontalCoffin\ci{\fonta\space CLOSING} 
\SetHorizontalCoffin\cii{\fontb THE}
\SetHorizontalCoffin\ciii{\fonta INNOVATION}
\SetHorizontalCoffin\civ{\fonta GAP}

\SetVerticalCoffin\slogan{\CoffinWidth\ciii+30pt}{\vspace*{25pt}\centering
\small\sffamily REIGNITING THE SPARK OF
THE GLOBAL ECONOMY\par}

% set the image coffin
\SetHorizontalCoffin\ImageCoffin{\space\space
  \includegraphics[width=100pt]{./images/innovation-book-cover.jpg}}
  
% set the author  
\SetHorizontalCoffin\AuthorCoffin{\fontb\centering JUDY ESTRIN\par}

% Now join all the coffins check the manual for the handles!    
\JoinCoffins\Result\ci
\JoinCoffins\Result[hc,b]    \cii[hc,t](0pt,-2mm)%the
\JoinCoffins\Result[l,b]       \ciii[l,t](15pt,-2mm)%innovation
\JoinCoffins\Result[\ciii-hc,\ciii-b] \civ[l,t](0pt,-2mm)
\JoinCoffins\Result[l,b]      \slogan[l,t](0pt,-2mm)
\JoinCoffins\Result[hc,b]   \AuthorCoffin[hc,t](0pt,-4mm)
\JoinCoffins\Result[r,b]      \ImageCoffin[l,b](0pt, 0pt)
   \fboxsep1pc
  \colorbox{black}{\color{white}\TypesetCoffin\Result}

% close the group we opened     
\egroup
\end{texexample}

Of course my general advice to anyone programming \latex is to always get professional advice on designing a book cover. Mathematicians, programmers and scientists are not the best of people to design book covers. They can come up with the code, but hardly succeed with the graphics aspects. There are also other methods to design and typeset book covers. An excellent package using \tikzname is \pkgname{bookcover} by Tibor Tómács. 


One tends to forget if the syntax requires to type \textit{t}, \textit{l} or \textit{l}, \textit{t} and this is a common issue with this type of commands. As we said before \latex stresses one’s memory to the limit. It can also be a bit confusing, as to when one needs to use a vertical rather than horizontal coffin.
    
If you stydy the code in Example~\ref{ex:covers} you will notice that the last box, has a width that was set using
\docAuxCommand*{CoffinWidth}. The package provides commands that provide the value of the coffin dimensions. These are described in the next section that together with some other auxiliary helper functions concludes our discussion of the package.

 \section{Measuring coffins}

 There are places in the design process where it is useful to be able to
 measure coffins outside of pole-setting procedures.

 \begin{docCommand}{CoffinDepth}{ \docAuxCommand*{CoffinDepth} \meta{coffin}}
   Calculates the depth (below the baseline) of the \meta{coffin}
   in a form suitable for use in a \meta{dimension expression}, for example
   |\setlength{\mylength}{\CoffinDepth\ExampleCoffin}|.
 \end{docCommand}

 \begin{docCommand}{CoffinHeight}{\docAuxCommand*{CoffinHeight} \meta{coffin}}
   Calculates the height (above the baseline) of the \meta{coffin}
   in a form suitable for use in a \meta{dimension expression}, for example
   |\setlength{\mylength}{\CoffinHeight\ExampleCoffin}|.
 \end{docCommand}

 \begin{docCommand}{CoffinTotalHeight}{\docAuxCommand*{CoffinTotalHeight} \meta{coffin}}
   Calculates the total height of the \meta{coffin}
   in a form suitable for use in a \meta{dimension expression}, for example
   |\setlength{\mylength}{\CoffinTotalHeight\ExampleCoffin}|.
 \end{docCommand}

 \begin{docCommand}{CoffinWidth}{\docAuxCommand*{CoffinWidth} \meta{coffin}}
   Calculates the width of the \meta{coffin} in a form
   suitable for use in a \meta{dimension expression}, for example
   |\setlength{\mylength}{\CoffinWidth\ExampleCoffin}|.
 \end{docCommand} 
    
\section{Debugging}

Debugging code that includes |coffin| functions is made easier when you can view information on the
poles. The pakage provides commands for both printing the information as well as viewing it on the screen.

\begin{docCommand}{DisplayCoffinHandles}{\meta{coffin}meta{color}}
This function first calculates the intersections between all of the hpolesi of the \meta{coffin} to
give a set of \meta{handles}. It then prints the \meta{coffin} at the current location in the source,
with the position of the \meta{handles} marked on the coffin. The \meta{handles} will be labelled
as part of this process: the locations of the \meta{handles} and the labels are both printed in
the \meta{color} specified. This is similar to the |\TypesetCoffin| function, except the former will also print
the handles. 
\end{docCommand}
  
\begin{docCommand}{MarkCoffinHandle}{\meta{coffin}\oarg[\meta{pole1}, \meta{pole2}] \marg{color}}  
This function first calculates the \meta{handle} for the \meta{coffin} as defined by the intersection
of \meta{pole1} and \meta{pole2}. It then marks the position of the \meta{handle} on the \meta{coffin}. The
\meta{handle} will be labelled as part of this process: the location of the \meta{handle} and the
label are both printed in the \meta{color} specified. If no \meta{poles} are give, the default (H,l) is
used.
\end{docCommand}
  
   \begin{figure}
     \hfil
     \SetHorizontalCoffin\ExampleCoffin
       {%
         \color{black!10!white}\rule{0.5 in}{1 in}^^A
         \color{black!20!white}\rule{0.5 in}{1 in}^^A
       }
     \begin{minipage}{0.4\textwidth}
       \DisplayCoffinHandles\ExampleCoffin{blue}
     \end{minipage}
     \hfil
     \begin{minipage}{0.4\textwidth}
       \RotateCoffin\ExampleCoffin{45}
       \DisplayCoffinHandles\ExampleCoffin{red!50!black}
     \end{minipage}
     \hfil
     \caption{Coffin rotation: left, unrotated; right, rotated by
       $45$\textdegree.}
     \label{fgr:rotation}
   \end{figure}
   
%\newpage 
%\newgeometry{margin=5pt,}  
%\null
%
%\newcommand\cbox[2][.8]{{\setlength\fboxsep{0pt}\colorbox[gray]{#1}{#2}}}
%
%
%  \NewCoffin \result
%  \NewCoffin \aaa
%  \NewCoffin \bbb
%  \NewCoffin \ccc
%  \NewCoffin \ddd
%  \NewCoffin \eee
%  \NewCoffin \fff
%  \NewCoffin \rulei
%  \NewCoffin \ruleii
%  \NewCoffin \ruleiii
%
%\SetHorizontalCoffin \result {}
%\SetHorizontalCoffin \aaa {\fontsize{52}{50}\sffamily\bfseries mep progress}
%\SetHorizontalCoffin \bbb {\fontsize{52}{50}\sffamily\bfseries habtoor city}%typographische}habtoor city
%\SetHorizontalCoffin \ccc {\fontsize{12}{10}\sffamily 
%                      \quad zeitschrift des bildungsverbandes der
%                      deutschen buchdrucker leipzig 
%                     \textbullet{} oktoberheft 1925}
%\SetHorizontalCoffin \ddd {\fontsize{28}{20}\sffamily report}%sonderheft}
%\SetVerticalCoffin \eee {180pt}
%                 {\raggedleft\fontsize{31}{36}\sffamily\bfseries 
%                      elementare\\
%                      typographie}
%\SetVerticalCoffin \fff {140pt}
%                 {\raggedright \fontsize{13}{14}\sffamily\bfseries 
%                       yannis lazarides \\
%                       nasser khalf \\
%                       kyriacos savva \\
%                       max burchartz \\
%                       el lissitzky \\
%                       ladislaus moholy-nagy \\
%                       moln\'ar f.~farkas \\
%                       johannes molzahn \\
%                       kurt schwitters \\
%                       mart stam \\
%                       ivan tschichold}
%
%\RotateCoffin \bbb {90}
%\RotateCoffin \ccc {270}
%
%\SetHorizontalCoffin \rulei  {\color{red}\rule{6.5in}{1pc}}
%\SetHorizontalCoffin \ruleii {\color{red}\rule{1pc}{20.5cm}}
%\SetHorizontalCoffin \ruleiii{\color{black}\rule{10pt}{152pt}}
%
%
%\JoinCoffins \result                \aaa 
%\JoinCoffins \result[\aaa-t,\aaa-r] \rulei   [b,r](0pt,2mm)
%\JoinCoffins \result[\aaa-b,\aaa-l] \bbb     [B,r](2pt,0pt)
%\JoinCoffins \result[\bbb-t,\bbb-r] \ruleii  [t,r](-2mm,0pt)
%\JoinCoffins \result[\aaa-B,\aaa-r] \ccc     [B,l](66pt,14pc)
%\JoinCoffins \result[\bbb-l,\ccc-B] \fff     [t,r](-2mm,0pt)
%\JoinCoffins \result[\fff-b,\fff-r] \ruleiii [b,l](2mm,0pt)
%\JoinCoffins \result[\ccc-r,\fff-l] \eee     [B,r]
%\JoinCoffins \result[\eee-T,\eee-r] \ddd     [B,r](0pt,4pc)
%
%
%
%\TypesetCoffin \result
%
%\restoregeometry


\chapter{LaTeX3 String Manipulation and other Goodies}

 \TeX{} associates each character with a category code: as such, there is no
 concept of a \enquote{string} as commonly understood in many other
 programming languages. However, there are places where we wish to manipulate
 token lists while in some sense \enquote{ignoring} category codes: this is
 done by treating token lists as strings in a \TeX{} sense.

 A \TeX{} string (and thus an \pkg{expl3} string) is a series of characters
 which have category code $12$ (\enquote{other}) with the exception of
 space characters which have category code $10$ (\enquote{space}). Thus
 at a technical level, a \TeX{} string is a token list with the appropriate
 category codes. In this documentation, these will simply be referred to as
 strings: note that they can be stored in token lists as normal.

 The functions documented here take literal token lists,
 convert to strings and then carry out manipulations. Thus they may
 informally be described as \enquote{ignoring} category code. Note that
 the functions \docAuxCommand*{cs_to_str:N}, \docAuxCommand*{tl_to_str:n}, \docAuxCommand*{tl_to_str:N} and
 \docAuxCommand*{token_to_str:N} (and variants) will generate strings from the appropriate
 input: these are documented in \pkg{l3basics}, \pkg{l3tl} and \pkg{l3token},
 respectively.

 \section{The first character from a string}

 \begin{docCommand}{str_head:n}{\docAuxCommand*{str_head:n} \marg{token list}}
   Converts the \meta{token list} into a string, as described for
   \docAuxCommand*{tl_to_str:n}. The \docAuxCommand*{str_head:n} function then leaves
   the first character of this string in the input stream.
   The \docAuxCommand*{str_tail:n} function leaves all characters except
   the first in the input stream. The first character may be
   a space. If the \meta{token list} argument is entirely empty,
   nothing is left in the input stream.
 \end{docCommand}

\begin{texexample}{Strings}{ex:strings}
\ExplSyntaxOn
\DeclareDocumentCommand\asentence{ m }{
  \str_head:n {#1}\par}
  
\asentence{This is something}  

\str_head:n{\This~is~something}\par
\str_tail:n{\This~is~something}
\ExplSyntaxOff


\end{texexample}

 \subsection{Tests on strings}

The package provides some very powerful commands that can be used in string comparisons. Internally the comparisons are carried out using |\pdfstrcmp|. This has some complications in LuaTeX. 

 \begin{docCommand}{str_if_eq_x:nnTF}{\docAuxCommand*{str_if_eq_p:nn} \marg{tl1} \marg{tl2}}
%     \docAuxCommand*{str_if_eq:nnTF} \Arg{tl_1} \Arg{tl_2} \Arg{true code} \Arg{false code}
%   \end{syntax}
   Compares the two \meta{token lists} on a character by character
   basis, and is \texttt{true} if the two lists contain the same
   characters in the same order. Thus for example
   \begin{verbatim}
     \str_if_eq_p:no { abc } { \tl_to_str:n { abc } }
   \end{verbatim}
   is logically \texttt{true}.
\end{docCommand}


\begin{texexample}{String comparisons}{ex:test}
\ExplSyntaxOn
\let\abc\empty
\str_if_eq_x:nnTF{abc}{abc}{\TRUE}{\FALSE}\par
\str_if_eq_x:nnTF{\abc}{\abc}{\TRUE}{\FALSE}
\ExplSyntaxOff
\end{texexample}

 \section{String manipulation}

 \begin{docCommand}{str_lower_case:n}{\marg{tokens}}
%      \str_lower_case:n, \str_lower_case:f, 
%      \str_upper_case:n, \str_upper_case:f
%   }
%   \begin{syntax}
%     \docAuxCommand*{str_lower_case:n} \Arg{tokens}
%     \docAuxCommand*{str_upper_case:n} \Arg{tokens}
%   \end{syntax}
   Converts the input \meta{tokens} to their string representation, as
   described for \docAuxCommand*{tl_to_str:n}, and then to the lower or upper
   case representation using a one-to-one mapping as described by the
   Unicode Consortium file |UnicodeData.txt|.
   
   These functions are intended for case changing programmatic data in
   places where upper/lower case distinctions are meaningful. One example
   would be automatically generating a function name from user input where
   some case changing is needed. In this situation the input is programmatic,
   not textual, case does have meaning and a language-independent one-to-one
   mapping is appropriate. For example
%   \begin{verbatim}
%     \docAuxCommand*_new_protected:Npn \myfunc:nn #1#2
%       {
%         \docAuxCommand*_set_protected:cpn
%           {
%             user
%             \str_upper_case:f { \tl_head:n {#1} }
%             \str_lower_case:f { \tl_tail:n {#1} }
%           }
%           { #2 }
%       }
%   \end{verbatim}
%   would be used to generate a function with an auto-generated name consisting
%   of the upper case equivalent of the supplied name followed by the lower
%   case equivalent of the rest of the input.
%   
%   These functions should \emph{not} be used for
%   \begin{itemize}
%     \item Caseless comparisons: use \docAuxCommand*{str_fold_case:n} for this
%       situation (case folding is district from lower casing).
%     \item Case changing text for typesetting: see the \docAuxCommand*{tl_lower_case:n(n)},
%       \docAuxCommand*{tl_upper_case:n(n)} and \docAuxCommand*{tl_mixed_case:n(n)} functions which
%       correctly deal with context-dependence and other factors appropriate
%       to text case changing.
%   \end{itemize}
%
%   \begin{texnote}
%     As with all \pkg{expl3} functions, the input supported by
%     \docAuxCommand*{str_fold_case:n} is \emph{engine-native} characters which are or
%     interoperate with \textsc{utf-8}. As such, when used with \pdfTeX{}
%     \emph{only} the Latin alphabet characters A--Z will be case-folded
%     (\emph{i.e.}~the \textsc{ascii} range which coincides with
%     \textsc{utf-8}). Full \textsc{utf-8} support is available with both
%     \XeTeX{} and \LuaTeX{}, subject only to the fact that \XeTeX{} in
%     particular has issues with characters of code above hexadecimal
%     $0\mathrm{xFFF}$ when interacting with \docAuxCommand*{tl_to_str:n}.
%   \end{texnote}
 \end{docCommand}
 
 A common programming task is to convert strings to either uppercase or lowercase equivalents.v
 \begin{texexample}{Converting strings to lower and uppercase}{ex:cases}%TOFIX 
 \ExplSyntaxOn
    \tl_tail:n {TEST} 
   
      \cs_new_protected:Npn \myfunc:nn #1#2
       {
         \cs_set_protected:cpn
           {
             user
             \str_upper_case:f { \tl_head:n {#1} }
             \str_lower_case:f { \tl_tail:n {#1} }
           }
           { #2 }
       }
\docAuxCommand*_new_protected:cpn {yiannis}{Lazarides}
 \ExplSyntaxOff
 \end{texexample}


\chapter{LaTeX3 properties}


 \LaTeX3 implements a \enquote{property list} data type, which contain
 an \emph{unordered list} of entries each of which consists of a \meta{key} and
 an associated \meta{value}. The \meta{key} and \meta{value} may both be
 any \meta{balanced text}. It is possible to map functions to property lists
 such that the function is applied to every key--value pair within
 the list.

 Each entry in a property list must have a unique \meta{key}: if an entry is
 added to a property list which already contains the \meta{key} then the new
 entry will overwrite the existing one. The \meta{keys} are compared on a
 string basis, using the same method as \docAuxCommand*{str_if_eq:nn}.

 Property lists are intended for storing key-based information for use within
 code.  This is in contrast to key--value lists, which are a form of
 \emph{input} parsed by the \pkgname{keys} module.

 \section{Creating and initialising property lists}

 \begin{docCommand}{prop_new:N or :c}{\meta{property list}}
   Creates a new \meta{property list} or raises an error if the name is
   already taken. The declaration is global. The \meta{property list} will
   initially contain no entries.
 \end{docCommand}

 \begin{docCommand}{prop_clear:N (:n:c) }{ \meta{property list}}
   Clears all entries from the \meta{property list}.
 \end{docCommand}

 \section{Adding entries to property lists}

 \begin{docCommand}{prop_put:Nnn}{ \meta{property list} \marg{key} \marg{value}}
 
   Adds an entry to the \meta{property list} which may be accessed
   using the \meta{key} and which has \meta{value}. Both the \meta{key}
   and \meta{value} may contain any \meta{balanced text}. The \meta{key}
   is stored after processing with \docAuxCommand*{tl_to_str:n}, meaning that
   category codes are ignored. If the \meta{key} is already present
   in the \meta{property list}, the existing entry is overwritten
   by the new \meta{value}.
 \end{docCommand}
 
 \begin{texexample}{Property lists}{ex:proplits}
 \ExplSyntaxOn
 \prop_new:N \proptemp
 \prop_put:Nnn \proptemp {symbolic}{true}
 \ExplSyntaxOff
\end{texexample}

 \section{Recovering values from property lists}

   \begin{docCommand}{prop_get:NnN}{ \meta{property list} \marg{key} \meta{tl var}}
   Recovers the \meta{value} stored with \meta{key} from the
   \meta{property list}, and places this in the \meta{token list
   variable}. If the \meta{key} is not found in the
   \meta{property list} then the \meta{token list variable} will
   contain the special marker \docAuxCommand*{q\_no\_value}. The \meta{token list
     variable} is set within the current \TeX{} group. See also
   \docAuxCommand*{prop_get:NnNTF}.
  \end{docCommand}


